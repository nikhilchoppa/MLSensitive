{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20171752-0c8a-4c37-aea0-af80eabe3878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8752644-b4ed-45c4-a604-1cef64ed2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xids.npy', 'rb') as fp:\n",
    "    Xids = np.load(fp)\n",
    "    \n",
    "with open('xmask.npy', 'rb') as fp:\n",
    "    Xmask = np.load(fp)\n",
    "    \n",
    "with open('labels.npy', 'rb') as fp:\n",
    "    labels = np.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d254e3cb-43c5-4e29-ac4f-011af79e71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "243f4744-80be-47f4-990b-741ef17bfbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(input_ids, mask, label):\n",
    "    return{'input_ids': input_ids, 'attention_mask': mask}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c853e162-e089-490f-b909-6656b6a75fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE= 32\n",
    "dataset = dataset.shuffle(10000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c1dd061-24c2-4e6f-9c50-294bd881f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0.8\n",
    "DS_LEN = len(list(dataset))\n",
    "\n",
    "train = dataset.take(round(DS_LEN*SPLIT))\n",
    "val = dataset.skip(round(DS_LEN*SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc4788d6-e95a-49c7-accc-64dca913ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7137bc3-5a88-4f1f-830d-6b8f630518c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4adf5b3-4246-4fe0-9407-df6048d2ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.keras.Input(shape=(30,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(30 ,), name='attention_mask', dtype='int32')\n",
    "\n",
    "embeddings = bert(input_ids, attention_mask=mask)[0]\n",
    "\n",
    "X = tf.keras.layers.Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu')(embeddings)\n",
    "X = tf.keras.layers.Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu')(X)\n",
    "X = tf.keras.layers.Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu')(X)\n",
    "X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
    "X = tf.keras.layers.BatchNormalization()(X)\n",
    "X = tf.keras.layers.Dense(128, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.1)(X)\n",
    "X = tf.keras.layers.Dense(32, activation='relu')(X)\n",
    "y = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(X)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "\n",
    "model.layers[2].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b96ca94f-6548-4526-a44e-da1d03d32ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_2 (TFBertModel)  multiple             108310272   ['input_ids[0][0]',              \n",
      "                                                                  'attention_mask[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 29, 50)       76850       ['tf_bert_model_2[1][0]']        \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 28, 50)       5050        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 27, 50)       5050        ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " global_max_pooling1d_8 (Global  (None, 50)          0           ['conv1d_2[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 50)          200         ['global_max_pooling1d_8[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          6528        ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)          (None, 128)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 32)           4128        ['dropout_116[0][0]']            \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 3)            99          ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,408,177\n",
      "Trainable params: 97,805\n",
      "Non-trainable params: 108,310,372\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87d4ecd5-5fb4-44a6-87f7-d31af72bfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd722876-6321-4c90-9daa-cf86c9af6d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_5\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 30) dtype=int64>]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\n\u001B[1;32m      5\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/var/folders/tz/z5m6fg7905g1b0zpb1g0vm680000gn/T/__autograph_generated_filegvbv2w6j.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/nikhilsaireddychoppa/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_5\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 30) dtype=int64>]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11654e1-688b-4c91-a2fa-6e14335ed3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88773df8-04a7-4160-a1ec-0914b4554bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML environment",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
