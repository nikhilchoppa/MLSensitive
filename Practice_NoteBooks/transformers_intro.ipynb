{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99bfc447-6831-48f2-8503-b7d396d56857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae247ba-ac0a-46f9-8d65-ce84b8409d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>withheld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-09T21:53:12.000Z</td>\n",
       "      <td>['1645183104896876545']</td>\n",
       "      <td>RT @nytimes: Elon Musk's many tweaks to Twitte...</td>\n",
       "      <td>1645183104896876545</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-09T21:53:12.000Z</td>\n",
       "      <td>['1645183104343048197']</td>\n",
       "      <td>RT @elonmusk: Tesla opening Megapack factory i...</td>\n",
       "      <td>1645183104343048197</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-09T21:53:12.000Z</td>\n",
       "      <td>['1645183103550496771']</td>\n",
       "      <td>RT @OmarRiverosays: BREAKING NEWS: Yahoo News ...</td>\n",
       "      <td>1645183103550496771</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-09T21:53:12.000Z</td>\n",
       "      <td>['1645183103332384769']</td>\n",
       "      <td>RT @blockkbusiness: Is it true Tesla is buildi...</td>\n",
       "      <td>1645183103332384769</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-09T21:53:12.000Z</td>\n",
       "      <td>['1645183102195494913']</td>\n",
       "      <td>RT @blockkbusiness: Is it true Tesla is buildi...</td>\n",
       "      <td>1645183102195494913</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at   edit_history_tweet_ids  \\\n",
       "0  2023-04-09T21:53:12.000Z  ['1645183104896876545']   \n",
       "1  2023-04-09T21:53:12.000Z  ['1645183104343048197']   \n",
       "2  2023-04-09T21:53:12.000Z  ['1645183103550496771']   \n",
       "3  2023-04-09T21:53:12.000Z  ['1645183103332384769']   \n",
       "4  2023-04-09T21:53:12.000Z  ['1645183102195494913']   \n",
       "\n",
       "                                                text                   id  \\\n",
       "0  RT @nytimes: Elon Musk's many tweaks to Twitte...  1645183104896876545   \n",
       "1  RT @elonmusk: Tesla opening Megapack factory i...  1645183104343048197   \n",
       "2  RT @OmarRiverosays: BREAKING NEWS: Yahoo News ...  1645183103550496771   \n",
       "3  RT @blockkbusiness: Is it true Tesla is buildi...  1645183103332384769   \n",
       "4  RT @blockkbusiness: Is it true Tesla is buildi...  1645183102195494913   \n",
       "\n",
       "  lang withheld  \n",
       "0   en      NaN  \n",
       "1   en      NaN  \n",
       "2   en      NaN  \n",
       "3   en      NaN  \n",
       "4   en      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('tesla_tweets.csv', sep='|')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704242c9-0509-49f6-881f-18bf31e668e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\") #uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b25d5e1b-3b36-4c18-a923-7f026706b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"We are going to implement sentiment analysis with BERT!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bcf17d2-29cb-471b-9d15-54d727145127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'going', 'to', 'implement', 'sentiment', 'analysis', 'with', 'bert', '!']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sample)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e8bf8f-d78b-4cd8-9849-558e533f2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2057, 2024, 2183, 2000, 10408, 15792, 4106, 2007, 14324, 999]\n"
     ]
    }
   ],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73ebe55c-2b36-4d81-a6c1-3f8bc0e10cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[PAD]', 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token, tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e21b87-fd26-439a-8e98-1e5f559ad5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[UNK]', 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.unk_token, tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf63e7a9-311b-4619-a235-70b38863c105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[CLS]', 101)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token, tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de397dc3-af4b-4110-b95f-b1c5f9251056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[SEP]', 102)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token, tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "929da06f-40f6-40f5-8667-f87f037d33ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]We are going to implement sentiment analysis with BERT![SEP]\n",
      "['[CLS]', 'we', 'are', 'going', 'to', 'implement', 'sentiment', 'analysis', 'with', 'bert', '!', '[SEP]']\n",
      "[101, 2057, 2024, 2183, 2000, 10408, 15792, 4106, 2007, 14324, 999, 102]\n"
     ]
    }
   ],
   "source": [
    "manual_sample = '[CLS]' + sample + '[SEP]'\n",
    "tokens = tokenizer.tokenize(manual_sample)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(manual_sample)\n",
    "print(tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "919eb967-bc6a-4bc8-8293-88523feeb089",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(sample, max_length=24, truncation=True, pad_to_max_length=True,\n",
    "                                add_special_tokens=True, return_attention_mask=True,\n",
    "                                return_tensors='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "054d186b-b9a2-4427-8ed7-892f4b74176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 24), dtype=int32, numpy=\n",
       "array([[  101,  2057,  2024,  2183,  2000, 10408, 15792,  4106,  2007,\n",
       "        14324,   999,   102,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 24), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 24), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1dc540b-d2b6-4cc4-96d7-cb0ad3f0a29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 24), dtype=int32, numpy=\n",
       "array([[  101,  2057,  2024,  2183,  2000, 10408, 15792,  4106,  2007,\n",
       "        14324,   999,   102,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ca99cc5-4c6b-414d-8b29-3c4075e5abef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 24), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454f58f-66e1-459e-9cc0-9a9b9b4526b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML environment",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
