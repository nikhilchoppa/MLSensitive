{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44c630f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datetime, timedelta\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtextblob\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tokenizer\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequence\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pad_sequences\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "import textblob\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962057c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API keys and access tokens (Replace with your own keys)\n",
    "consumer_key = 'aUuTOXF4xuQaxHPoTj1SXs15y'\n",
    "consumer_secret = 'VPWbSa7QtH3y1pFDiNruhzKZVwyFFZEEVIJx3IcyheFPpArvPU'\n",
    "access_token = '943525676186869760-S9yLEmxBn6vZraC6boeSi258UJsRHtj'\n",
    "access_token_secret = 'uOF58rEbsvV8AhKDUryl35IVJpZXxJwbWbvhRGhV7jTTR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe82768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set up Twitter API\n",
    "def create_api():\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean tweets\n",
    "def clean_tweet(tweet):\n",
    "    # Remove mentions, URLs, and non-alphanumeric characters\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch tweets using Twitter API\n",
    "def get_tweets(api, query, count=10000):\n",
    "    tweets = []\n",
    "\n",
    "    # Get the datetime for 5 hours ago\n",
    "    since_datetime = datetime.now() - timedelta(hours=6)\n",
    "    since_str = since_datetime.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Find a tweet from around 5 hours ago\n",
    "    tweets_around_five_hours_ago = api.search_tweets(q=query, count=1, lang=\"en\", tweet_mode=\"extended\",\n",
    "                                                     until=since_str)\n",
    "    if tweets_around_five_hours_ago:\n",
    "        since_id = tweets_around_five_hours_ago[0].id\n",
    "    else:\n",
    "        since_id = None\n",
    "\n",
    "    # Use the since_id parameter to fetch tweets from the past 5 hours\n",
    "    fetched_tweets = api.search_tweets(q=query, count=count, lang=\"en\", tweet_mode=\"extended\", since_id=since_id)\n",
    "\n",
    "    # Clean and store fetched tweets\n",
    "    for tweet in fetched_tweets:\n",
    "        parsed_tweet = {'text': clean_tweet(tweet.full_text)}\n",
    "        tweets.append(parsed_tweet)\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caab83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and label tweets for training data\n",
    "def get_labeled_tweets(api, query, count=10000):\n",
    "    # Fetch tweets using the existing get_tweets function\n",
    "    tweets = get_tweets(api, query, count)\n",
    "\n",
    "    # Preprocess and clean tweets\n",
    "    cleaned_tweets = [clean_tweet(tweet['text']) for tweet in tweets]\n",
    "\n",
    "    # Label the cleaned tweets (e.g., using a pre-trained sentiment analysis model)\n",
    "    # I will use TextBlob, a simple rule-based sentiment analysis library\n",
    "    \n",
    "\n",
    "    def label_sentiment(text):\n",
    "        sentiment_score = TextBlob(text).sentiment.polarity\n",
    "        if sentiment_score < -0.05:\n",
    "            return 0  # negative\n",
    "        elif sentiment_score > 0.05:\n",
    "            return 2  # positive\n",
    "        else:\n",
    "            return 1  # neutral\n",
    "\n",
    "    labeled_tweets = [(tweet, label_sentiment(tweet)) for tweet in cleaned_tweets]\n",
    "    return labeled_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a pre-trained LSTM model\n",
    "def load_pretrained_lstm_model(model_path):\n",
    "    model = load_model(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad4ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train a custom LSTM model\n",
    "def create_and_train_model(train_data, train_labels):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(train_data)\n",
    "    max_length = max([len(s.split()) for s in train_data])\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(train_data)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, 64, input_length=max_length),\n",
    "        LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(padded_sequences, train_labels, epochs=5, batch_size=32)\n",
    "\n",
    "    return model, tokenizer, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare and predict the sentiment using the custom LSTM model\n",
    "def predict_sentiment(model, tokenizer, max_length, text):\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return np.argmax(prediction, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf014b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform sentiment analysis\n",
    "def sentiment_analysis(query):\n",
    "    # Load the pre-trained LSTM model and its corresponding tokenizer and max_length\n",
    "    model = load_pretrained_lstm_model('pretrained_lstm_model.h5')\n",
    "    tokenizer = Tokenizer()  # Load the tokenizer you used to train the model\n",
    "    max_length = 50  # Set the max_length to the value used during training\n",
    "    api = create_api()\n",
    "    tweets = get_tweets(api, query)\n",
    "\n",
    "    tweet_sentiments = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "\n",
    "    for tweet in tweets:\n",
    "        sentiment = predict_sentiment(model, tokenizer, max_length, tweet['text'])\n",
    "\n",
    "        if sentiment == 0:\n",
    "            tweet_sentiments['negative'] += 1\n",
    "        elif sentiment == 1:\n",
    "            tweet_sentiments['neutral'] += 1\n",
    "        elif sentiment == 2:\n",
    "            tweet_sentiments['positive'] += 1\n",
    "\n",
    "    # Calculate sentiment percentages\n",
    "    tweet_sentiments_percentages = {k: v / len(tweets) * 100 for k, v in tweet_sentiments.items()}\n",
    "\n",
    "    # Print sentiment percentages\n",
    "    print(\"Sentiment analysis for\", query)\n",
    "    for sentiment, percentage in tweet_sentiments_percentages.items():\n",
    "        print(f\"{sentiment.capitalize()}: {percentage:.2f}%\")\n",
    "\n",
    "    # Create a pie chart to visualize sentiment percentages\n",
    "    plt.pie(tweet_sentiments_percentages.values(), labels=tweet_sentiments_percentages.keys(), autopct='%1.1f%%',\n",
    "            startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title(f\"Sentiment analysis for {query}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac73f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to take user input and call the sentiment_analysis function\n",
    "if __name__ == \"__main__\":\n",
    "    query = input(\"Enter the stock or crypto symbol: \")\n",
    "    # Fetch and label tweets for training data\n",
    "    api = create_api()\n",
    "    labeled_tweets = get_labeled_tweets(api, query)\n",
    "    train_data, train_labels = zip(*labeled_tweets)\n",
    "\n",
    "    # Train the LSTM model using the labeled tweets\n",
    "    model, tokenizer, max_length = create_and_train_model(train_data, train_labels)\n",
    "\n",
    "    # Perform sentiment analysis using the trained model\n",
    "    sentiment_analysis(query)\n",
    "\n",
    "    print(\"Note: This sentiment analysis might not accurately \"\n",
    "          \"capture sarcasm or nuanced expressions of sentiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073795c-c381-45ad-899d-e14555bfd39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ML environment",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
