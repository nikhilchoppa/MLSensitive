{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f59b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tweepy\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5030e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API keys and access tokens\n",
    "consumer_key = 'aUuTOXF4xuQaxHPoTj1SXs15y'\n",
    "consumer_secret = 'VPWbSa7QtH3y1pFDiNruhzKZVwyFFZEEVIJx3IcyheFPpArvPU'\n",
    "access_token = '943525676186869760-S9yLEmxBn6vZraC6boeSi258UJsRHtj'\n",
    "access_token_secret = 'uOF58rEbsvV8AhKDUryl35IVJpZXxJwbWbvhRGhV7jTTR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set up Twitter API\n",
    "def create_api():\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean tweets\n",
    "def clean_tweet(tweet):\n",
    "    # Remove mentions, URLs, and non-alphanumeric characters\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch tweets using Twitter API\n",
    "def get_tweets(api, query, count=10000):\n",
    "    tweets = []\n",
    "\n",
    "    # Get the datetime for 5 hours ago\n",
    "    since_datetime = datetime.now() - timedelta(hours=6)\n",
    "    since_str = since_datetime.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Find a tweet from around 5 hours ago\n",
    "    tweets_around_five_hours_ago = api.search_tweets(q=query, count=1, lang=\"en\", tweet_mode=\"extended\",\n",
    "                                                     until=since_str)\n",
    "    if tweets_around_five_hours_ago:\n",
    "        since_id = tweets_around_five_hours_ago[0].id\n",
    "    else:\n",
    "        since_id = None\n",
    "\n",
    "    # Use the since_id parameter to fetch tweets from the past 5 hours\n",
    "    fetched_tweets = api.search_tweets(q=query, count=count, lang=\"en\", tweet_mode=\"extended\", since_id=since_id)\n",
    "\n",
    "    # Clean and store fetched tweets\n",
    "    for tweet in fetched_tweets:\n",
    "        parsed_tweet = {'text': clean_tweet(tweet.full_text)}\n",
    "        tweets.append(parsed_tweet)\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c193c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the pre-trained DistilBert model and tokenizer\n",
    "def load_model():\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac92aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform sentiment analysis\n",
    "# Function to perform sentiment analysis\n",
    "def sentiment_analysis(query):\n",
    "    api = create_api()\n",
    "    tweets = get_tweets(api, query)\n",
    "    model, tokenizer = load_model()\n",
    "\n",
    "    tweet_sentiments = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "    neutral_threshold = 0.05\n",
    "\n",
    "    # Classify tweet sentiment using the model\n",
    "    for tweet in tweets:\n",
    "        inputs = tokenizer.encode_plus(tweet['text'], return_tensors='tf', padding=True, truncation=True)\n",
    "        outputs = model(inputs)\n",
    "        logits = outputs.logits.numpy()\n",
    "        probs = tf.nn.softmax(logits, axis=1).numpy()[0]\n",
    "\n",
    "        if probs[1] - probs[0] > neutral_threshold:\n",
    "            tweet_sentiments['positive'] += 1\n",
    "        elif probs[0] - probs[1] > neutral_threshold:\n",
    "            tweet_sentiments['negative'] += 1\n",
    "        else:\n",
    "            tweet_sentiments['neutral'] += 1\n",
    "\n",
    "    # Calculate sentiment percentages\n",
    "    tweet_sentiments_percentages = {k: v / len(tweets) * 100 for k, v in tweet_sentiments.items()}\n",
    "\n",
    "    # Print sentiment percentages\n",
    "    print(\"Sentiment analysis for\", query)\n",
    "    for sentiment, percentage in tweet_sentiments_percentages.items():\n",
    "        print(f\"{sentiment.capitalize()}: {percentage:.2f}%\")\n",
    "\n",
    "    # Create a pie chart to visualize sentiment percentages\n",
    "    plt.pie(tweet_sentiments_percentages.values(), labels=tweet_sentiments_percentages.keys(), autopct='%1.1f%%', startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title(f\"Sentiment analysis for {query}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de473e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to take user input and call the sentiment_analysis function\n",
    "if __name__ == \"__main__\":\n",
    "    query = input(\"Enter the stock or crypto symbol: \")\n",
    "    sentiment_analysis(query)\n",
    "    print(\"Note: This sentiment analysis might not accurately \\n\"\n",
    "          \"capture sarcasm or nuanced expressions of sentiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b3189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
